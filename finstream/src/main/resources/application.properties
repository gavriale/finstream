# ===== App =====
spring.application.name=finstream
server.port=8080

# ===== Postgres (Timescale) =====
spring.datasource.url=jdbc:postgresql://localhost:5433/finstream
spring.datasource.username=postgres
spring.datasource.password=postgres
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.hikari.minimum-idle=2
spring.datasource.hikari.connection-timeout=20000
spring.sql.init.mode=never

spring.flyway.enabled=true
spring.flyway.baseline-on-migrate=true
spring.flyway.locations=classpath:db/migration

# ===== Redis =====
spring.data.redis.host=localhost
spring.data.redis.port=6379
spring.data.redis.timeout=2s
# If Redis isn't running yet and you just want app up:
# management.health.redis.enabled=false

# ===== Kafka general =====
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.client-id=finstream-app

# ===== Producer =====
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.producer.acks=all
spring.kafka.producer.properties.enable.idempotence=true
spring.kafka.producer.properties.compression.type=snappy
spring.kafka.producer.properties.linger.ms=10
spring.kafka.producer.properties.batch.size=131072
# Safer ordering during retries ? set to 1 (you had 5). Bump later if you need throughput.
spring.kafka.producer.properties.max.in.flight.requests.per.connection=1
spring.kafka.producer.properties.delivery.timeout.ms=120000
# You're disabling type headers, so we must tell the consumer what type to deserialize into:
spring.kafka.producer.properties.spring.json.add.type.headers=false

# ===== Consumer =====
spring.kafka.consumer.group-id=finstream-dev
# For local dev you usually want to see messages from the beginning:
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
# Since producer omits type headers, set a default target type:
spring.kafka.consumer.properties.spring.json.use.type.headers=false
spring.kafka.consumer.properties.spring.json.value.default.type=com.finstream.model.TickV1

# ===== Listener container (Spring Kafka) =====
spring.kafka.listener.ack-mode=RECORD
spring.kafka.listener.concurrency=1

# === Finnhub ===
finnhub.base-url=https://finnhub.io/api/v1
finnhub.api-key=${FINNHUB_API_KEY}   # set as an env var for safety


logging.level.reactor.netty.http.client=DEBUG
logging.level.org.springframework.web.reactive.function.client=DEBUG

# ===== Actuator / Prometheus =====
#management.endpoints.web.exposure.include=health,info,metrics,prometheus
#management.endpoint.health.show-details=always
#management.metrics.export.prometheus.enabled=true
#management.server.port=8080

